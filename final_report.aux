\relax 
\citation{DFT_fig}
\citation{DFT_fig2}
\citation{DFT_fig3}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{4}}
\citation{Szegedy_2016_CVPR}
\citation{ILSVRC15}
\citation{GH_CNN}
\citation{StanfordCS231_1}
\citation{StanfordCS231_1}
\citation{StanfordCS231_1}
\citation{StanfordCS231_1}
\citation{StanfordCS231_1}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background, Computer Vision}{5}}
\newlabel{comp_vis_back}{{2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Deep Learning Preliminaries}{5}}
\newlabel{dlp}{{2.1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Convolutional Networks}{5}}
\newlabel{Cnn_section}{{2.2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Regular Neural Network (Left) \cite  {StanfordCS231_1} , CNN (right) \cite  {StanfordCS231_1}.\relax }}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{CNNvsNN}{{1}{5}}
\citation{StanfordCS231_conv_filter}
\citation{StanfordCS231_max_pool}
\citation{StanfordCS231_conv_filter}
\citation{StanfordCS231_max_pool}
\citation{DBLP:journals/corr/abs-1710-09829}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{DBLP:journals/corr/RedmonDGF15}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{Uijlings2013}
\citation{Felzenszwalb2004}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Convolutional Layers}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces CNN Filter (left) \cite  {StanfordCS231_conv_filter}, Max Pooling \cite  {StanfordCS231_max_pool}\relax }}{6}}
\newlabel{CNN_filter}{{2}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Pooling Layers}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Image Detection}{6}}
\newlabel{Image_det}{{2.3}{6}}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{DBLP:journals/corr/GirshickDDM13}
\citation{DBLP:journals/corr/Girshick15}
\citation{DBLP:journals/corr/HeZR014}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}R-CNN}{7}}
\newlabel{rcnn}{{2.3.1}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces R-CNN Region Proposal \& Architecture \cite  {DBLP:journals/corr/GirshickDDM13}\relax }}{7}}
\newlabel{Selective_search}{{3}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Fast-RCNN}{7}}
\newlabel{Fast_RCNN}{{2.3.2}{7}}
\newlabel{multi-task_loss}{{1}{7}}
\citation{DBLP:journals/corr/Girshick15}
\citation{DBLP:journals/corr/Girshick15}
\citation{DBLP:journals/corr/Girshick15}
\citation{Uijlings2013}
\citation{DBLP:journals/corr/RenHG015}
\citation{DBLP:journals/corr/Girshick15}
\citation{DBLP:journals/corr/Girshick15}
\newlabel{bbox_loss}{{2}{8}}
\newlabel{multi-task_s}{{3}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Fast R-CNN Architecture \cite  {DBLP:journals/corr/Girshick15}\relax }}{8}}
\newlabel{Fast_RNN_fig}{{4}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Faster R-CNN}{8}}
\newlabel{Faster_rcnn}{{2.3.3}{8}}
\citation{DBLP:journals/corr/LongSD14}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Fast R-CNN Architecture \cite  {DBLP:journals/corr/Girshick15}\relax }}{9}}
\newlabel{Faster_rnn_fig}{{5}{9}}
\newlabel{multi-task_loss_fast_rcnn}{{4}{9}}
\newlabel{bounding_box_loss}{{5}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Image Segmentation}{9}}
\newlabel{image_seg}{{2.4}{9}}
\citation{DBLP:journals/corr/CordtsORREBFRS16}
\citation{DBLP:journals/corr/LongSD14}
\citation{DBLP:journals/corr/CordtsORREBFRS16}
\citation{DBLP:journals/corr/LongSD14}
\citation{Wan:2013:RNN:3042817.3043055}
\citation{JMLR:v15:srivastava14a}
\citation{DBLP:journals/corr/LongSD14}
\citation{Bishop:2006:PRM:1162264}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Image Segmentation \cite  {DBLP:journals/corr/CordtsORREBFRS16}, Convolutional Heat Map \cite  {DBLP:journals/corr/LongSD14}\relax }}{10}}
\newlabel{cityscapes_data}{{6}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Instance Segmentation}{10}}
\citation{DBLP:journals/corr/HeGDG17}
\citation{DBLP:journals/corr/HeGDG17}
\citation{DBLP:journals/corr/RenHG015}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Mask R-CNN}{11}}
\newlabel{mask_rcnn}{{2.5.1}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Mask R-CNN \cite  {DBLP:journals/corr/HeGDG17}\relax }}{11}}
\newlabel{Mask_rcnn_arch}{{7}{11}}
\newlabel{maskrcnnloss}{{6}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background, SLAM}{11}}
\newlabel{back_slam}{{3}{11}}
\citation{opencv_camera_article}
\citation{opencv_camera_article}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Sensors}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Intel Realsense Camera (ZR300)\relax }}{12}}
\newlabel{realsense_camera}{{8}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Camera Distortion}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces No Distortion (left)\cite  {opencv_camera_article}, Positive/negative radial distortion (middle/right)\relax }}{12}}
\newlabel{distortion}{{9}{12}}
\newlabel{raddis}{{7}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Camera to World Frame}{13}}
\newlabel{cam2world}{{3.2}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Calculating the 3D Ray}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Pinhole Camera Model\relax }}{13}}
\newlabel{pinhole_model}{{10}{13}}
\newlabel{camera_scale}{{8}{13}}
\newlabel{camera_scale2}{{9}{13}}
\newlabel{to_3d_ray}{{10}{13}}
\citation{Okvis_1}
\citation{Okvis_1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Calculating the 3D Location}{14}}
\newlabel{camera_add_depth}{{11}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Projecting to World Frame}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces World vs Camera Frame (left)\cite  {Okvis_1}, Hamiltonian Quaternion (right)\relax }}{14}}
\newlabel{quat_wcs}{{11}{14}}
\newlabel{quaternion}{{12}{14}}
\newlabel{matmul_w2c}{{13}{14}}
\newlabel{invert_tmatrix}{{15}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Camera to World Summary}{15}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Algorithm to transform camera point to world frame\relax }}{15}}
\newlabel{alg:weights}{{1}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}World to Camera Frame}{15}}
\newlabel{w_c_frame}{{3.4}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Bicycle States}{15}}
\newlabel{states_1}{{16}{15}}
\newlabel{states_2}{{17}{15}}
\citation{F_Durr_1}
\citation{Okvis_1}
\citation{F_Durr_Pt1}
\citation{F_Durr_Pt1}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Algorithm to transform world point to camera frame\relax }}{16}}
\newlabel{alg:weights}{{2}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}The SLAM Problem}{16}}
\newlabel{measurement_model}{{18}{16}}
\citation{Okvis_1}
\citation{BRISK}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Left: Convergence in landmark uncertainty. Over time, standard deviations reduce monotonically to a lower bound \cite  {F_Durr_Pt1}. Right: Error between estimated and true landmarks is common.\relax }}{17}}
\newlabel{slam_prob_fig}{{12}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Batch NonLinear Least Squares}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}Frame to Frame Matching}{17}}
\newlabel{BRISK_section}{{3.6.2}{17}}
\@writefile{toc}{\contentsline {paragraph}{Keypoint Detection}{17}}
\citation{opencv_harris_article}
\citation{opencv_harris_article}
\citation{BRISK}
\citation{BRISK}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Left: Structure Tensor Eigenvalues, Right: Harris corner detection result \cite  {opencv_harris_article} \relax }}{18}}
\newlabel{Harris}{{13}{18}}
\@writefile{toc}{\contentsline {paragraph}{Keypoint Matching}{18}}
\citation{Furgale}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Left: Brisk keypoint matching example, Right: Brisk Sampling Pattern \cite  {BRISK} \relax }}{19}}
\newlabel{Brisk}{{14}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}Camera Re-projection Error}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.4}IMU Kinematics}{19}}
\newlabel{imu_kin}{{28}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.5}IMU Kinematics Linearised}{19}}
\citation{Okvis_1}
\citation{Ped_tract}
\citation{Bradski98computervision}
\citation{Ped_tract}
\newlabel{imu_error_}{{32}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Background, Object Tracking}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}CamShift}{20}}
\citation{Ped_tract}
\citation{Ped_tract}
\citation{Ped_tract}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Object Tracking Summary}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Pedestrian Tracking Module \cite  {Ped_tract} \relax }}{21}}
\newlabel{Ped_tr_mod_fig}{{15}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Ethics}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Modification for Military Purposes}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Other Ethics Issues}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Poor Sensors}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Depth Camera Output\relax }}{22}}
\newlabel{DCO}{{16}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Left: Bottle with working depth, Right: Incorrect Depth measurement. In both cases the white dot is the bottle's location, the green dot is the Kalman filter prediction, blue dots are previous locations (the bottle did not move), and the white line is the camera location.\relax }}{23}}
\newlabel{bottle}{{17}{23}}
\newlabel{check__depth_eq1}{{35}{23}}
\newlabel{check__depth_eq2}{{36}{23}}
\citation{kcf}
\newlabel{check__depth_eq2}{{37}{24}}
\newlabel{check__depth_eq3}{{38}{24}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.0.1}Depth stuff summary}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Frame-to-Frame Tracking}{24}}
\citation{kcf}
\citation{kcf}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces ROI Old to New Frame Example.\relax }}{25}}
\newlabel{roi_match}{{18}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Kernelised Correlation Filter}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Illustration of circulant matrix.\cite  {kcf}\relax }}{25}}
\newlabel{circular_data}{{19}{25}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Kernels}{26}}
\newlabel{kcf_kernels}{{7.1.1}{26}}
\newlabel{gauss_kernel}{{45}{26}}
\newlabel{kernel_soln}{{47}{26}}
\newlabel{al_soln}{{48}{26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Detection}{26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.3}Modifications}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}BRISK - Selector}{27}}
\newlabel{BRISK_matching}{{7.2}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Class Matching}{27}}
\newlabel{class_matching}{{7.3}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Kalman Filter ROI Matching}{27}}
\newlabel{kalman_matching}{{7.4}{27}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.1}Kalman Predictive Step}{27}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.2}Kalman Update Step}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.3}Kalman Equations}{28}}
\newlabel{Kalman_pred_eq}{{59}{28}}
\newlabel{kalman_update_equs}{{60}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.4}Kalman Matching ROIS}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}ROI Lives}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6}Combining Matching Methods}{29}}
\newlabel{matching_combining_methods}{{7.6}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Movement Prediction}{30}}
\@writefile{toc}{\contentsline {section}{\numberline {9}System Evaluation}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Mask-RCNN}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Okvis with Dynamic Objects}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Depth Camera}{30}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Ethics Checklist}{31}}
\gdef \LT@i {\LT@entry 
    {1}{388.37627pt}\LT@entry 
    {1}{29.47182pt}\LT@entry 
    {1}{29.47182pt}}
\bibstyle{ieeetr}
\bibdata{bibliography.bib}
\bibcite{DFT_fig}{1}
\bibcite{DFT_fig2}{2}
\bibcite{DFT_fig3}{3}
\bibcite{Szegedy_2016_CVPR}{4}
\bibcite{ILSVRC15}{5}
\bibcite{GH_CNN}{6}
\bibcite{StanfordCS231_1}{7}
\bibcite{StanfordCS231_conv_filter}{8}
\bibcite{StanfordCS231_max_pool}{9}
\bibcite{DBLP:journals/corr/abs-1710-09829}{10}
\bibcite{DBLP:journals/corr/GirshickDDM13}{11}
\bibcite{DBLP:journals/corr/RedmonDGF15}{12}
\bibcite{Uijlings2013}{13}
\bibcite{Felzenszwalb2004}{14}
\bibcite{DBLP:journals/corr/Girshick15}{15}
\bibcite{DBLP:journals/corr/HeZR014}{16}
\bibcite{DBLP:journals/corr/RenHG015}{17}
\bibcite{DBLP:journals/corr/LongSD14}{18}
\bibcite{DBLP:journals/corr/CordtsORREBFRS16}{19}
\bibcite{Wan:2013:RNN:3042817.3043055}{20}
\bibcite{JMLR:v15:srivastava14a}{21}
\bibcite{Bishop:2006:PRM:1162264}{22}
\bibcite{DBLP:journals/corr/HeGDG17}{23}
\bibcite{opencv_camera_article}{24}
\bibcite{Okvis_1}{25}
\bibcite{F_Durr_1}{26}
\bibcite{F_Durr_Pt1}{27}
\bibcite{BRISK}{28}
\bibcite{opencv_harris_article}{29}
\bibcite{Furgale}{30}
\bibcite{Ped_tract}{31}
\bibcite{Bradski98computervision}{32}
\bibcite{kcf}{33}
